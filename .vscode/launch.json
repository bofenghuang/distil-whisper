{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": true
        },
        {
            "name": "Python: Accelerate",
            "type": "debugpy",
            "module": "accelerate.commands.launch",
            "request": "launch",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--multi_gpu",
                "--num_processes", "2",
                "--main_process_port", "12345",
                "${file}",
            ]
        },
        {
            "name": "Debug pseudo labelling",
            "type": "debugpy",
            "module": "accelerate.commands.launch",
            "request": "launch",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--multi_gpu",
                // "--num_processes", "1",
                "--num_processes", "2",
                "--main_process_port", "12345",
                // "${file}",
                "${workspaceFolder}/training/run_pseudo_labelling_b.py",
                "--model_name_or_path", "openai/whisper-large-v3",
                "--dataset_file", "/projects/bhuang/corpus/speech/nemo_manifests/mozilla-foundation/common_voice_17_0/fr/train/train_mozilla-foundation_common_voice_17_0_manifest.json",
                "--max_samples_per_split", "128",
                "--output_dir", "tmp_debug",
                "--audio_column_name", "audio_filepath",
                "--id_column_name", "id",
                "--duration_column_name", "duration",
                "--sort_by_duration", "True",
                "--preprocessing_num_workers", "64",
                "--pad_to_multiple_of", "64",
                "--dataloader_num_workers", "8",
                "--dtype", "float16",
                "--attn_implementation", "flash_attention_2",
                "--per_device_eval_batch_size", "32",
                "--language", "fr",
                "--task", "transcribe",
                "--return_timestamps", "True",
                "--max_label_length", "448",
                "--generation_num_beams", "1",
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "4,5",
                "HF_HOME": "/projects/bhuang/.cache/huggingface",
            }
        },
        {
            "name": "Debug distillation",
            "type": "debugpy",
            "module": "accelerate.commands.launch",
            "request": "launch",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                // "--multi_gpu",
                "--num_processes", "1",
                // "--num_processes", "2",
                "--main_process_port", "12345",
                // "${file}",
                "${workspaceFolder}/training/run_distillation_b.py",
                "--model_name_or_path", "/projects/bhuang/models/asr/whisper/openai-whisper_large_v3_dec2_init",
                "--teacher_model_name_or_path", "openai/whisper-large-v3",
                "--apply_spec_augment", "True",
                "--train_file", "/projects/bhuang/corpus/speech/nemo_manifests/mozilla-foundation/common_voice_17_0/fr/train_concatenated/train_mozilla-foundation_common_voice_17_0_manifest_whisper_large_v3_norm_wer_filt_wer.json",
                "--validation_file", "/projects/bhuang/corpus/speech/nemo_manifests/mozilla-foundation/common_voice_17_0/fr/validation/validation_mozilla-foundation_common_voice_17_0_manifest.json+/projects/bhuang/corpus/speech/nemo_manifests/mozilla-foundation/common_voice_17_0/fr/test/test_mozilla-foundation_common_voice_17_0_manifest.json",
                // "--max_samples_per_split", "128",
                "--audio_column_name", "audio_filepath",
                "--text_column_name", "whisper_transcript",
                "--eval_text_column_name", "text",
                "--duration_column_name", "duration",
                "--prev_text_column_name", "prev_whisper_transcript",
                "--condition_on_prev_column_name", "condition_on_prev",
                "--language_column_name", "_language",
                "--max_label_length", "448",
                "--wer_threshold", "10",
                "--timestamp_probability", "0.5",
                "--condition_on_prev_probability", "1.0",
                "--return_timestamps", "False",
                // "--language", "fr",
                "--task", "transcribe",
                // "--sort_by_duration", "True",
                "--preprocessing_num_workers", "32",
                "--dataloader_num_workers", "1",
                "--pad_to_multiple_of", "64",
                "--output_dir", "tmp_debug",
                "--overwrite_output_dir", "True",
                "--num_train_epochs", "1",
                "--per_device_train_batch_size", "4",
                "--per_device_eval_batch_size", "2",
                "--gradient_accumulation_steps", "1",
                "--freeze_encoder", "True",
                "--freeze_embed_positions", "True",
                "--kl_weight", "1.0",
                "--temperature", "2.0",
                "--dtype", "bfloat16",
                "--learning_rate", "1e-4",
                "--adam_beta1", "0.9",
                "--adam_beta2", "0.95",
                "--warmup_steps", "10",
                "--lr_scheduler_type", "cosine",
                "--gradient_checkpointing", "True",
                // "--attn_implementation", "flash_attention_2",
                "--attn_implementation", "sdpa",
                "--logging_steps", "1",
                "--eval_steps", "1",
                // "--save_steps", "10",
                "--predict_with_generate", "True",
                "--generation_num_beams", "1",
                "--do_train", "True",
                "--do_eval", "True",
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "4,5",
                "HF_HOME": "/projects/bhuang/.cache/huggingface",
                "WANDB_DISABLED": "true",
            }
        },
        {
            "name": "Debug evaluation (short form)",
            "type": "debugpy",
            "module": "accelerate.commands.launch",
            "request": "launch",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--num_processes", "1",
                "--main_process_port", "12345",
                // "${file}",
                // "${workspaceFolder}/training/run_eval.py",
                "${workspaceFolder}/training/run_eval_b.py",
                // "--model_name_or_path", "openai/whisper-large-v3",
                "--model_name_or_path", "eustlb/distil-large-v3-fr",
                "--dtype", "float16",
                "--attn_implementation", "sdpa",
                "--use_pipeline", "False",
                // "--dataset_file", "/projects/bhuang/corpus/speech/nemo_manifests/speech-recognition-community-v2/dev_data/fr/validation/validation_speech-recognition-community-v2_dev_data_manifest.json",
                // "--dataset_file", "/projects/bhuang/corpus/speech/nemo_manifests/mozilla-foundation/common_voice_17_0/fr/test/test_mozilla-foundation_common_voice_17_0_manifest.json",
                // "--audio_column_name", "audio_filepath",
                // "--text_column_name", "text",
                "--dataset_name", "google/fleurs",
                "--dataset_config_name", "fr_fr",
                "--dataset_split_name", "test",
                "--text_column_name", "transcription",
                "--output_file", "/home/bhuang/distil-whisper/training/outputs/tmp_output.json",
                "--samples_per_dataset", "8",
                "--only_short_form", "True",
                "--streaming", "True",
                // "--streaming", "False",
                "--batch_size", "2",
                "--language", "french",
                "--task", "transcribe",
                "--return_timestamps", "False",
                "--num_beams", "1",
                "--generation_max_length", "256",
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "4",
                "HF_HOME": "/projects/bhuang/.cache/huggingface",
            }
        },
        {
            "name": "Debug evaluation (long form chunked)",
            "type": "debugpy",
            "module": "accelerate.commands.launch",
            "request": "launch",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--num_processes", "1",
                "--main_process_port", "12345",
                // "${file}",
                "${workspaceFolder}/training/run_eval_b.py",
                "--model_name_or_path", "openai/whisper-large-v3",
                "--dtype", "bfloat16",
                "--attn_implementation", "sdpa",
                "--use_pipeline", "True",
                "--chunk_length_s", "30",
                "--dataset_file", "/projects/bhuang/corpus/speech/nemo_manifests/speech-recognition-community-v2/dev_data/fr/validation/validation_speech-recognition-community-v2_dev_data_manifest.json",
                "--audio_column_name", "audio_filepath",
                "--streaming", "True",
                "--output_file", "/home/bhuang/distil-whisper/training/outputs/tmp.json",
                "--batch_size", "1",
                "--language", "french",
                "--task", "transcribe",
                "--return_timestamps", "False",
                "--num_beams", "1",
                "--generation_max_length", "256",
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "4",
                "HF_HOME": "/projects/bhuang/.cache/huggingface",
            }
        }
    ]
}